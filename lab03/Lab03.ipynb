{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> LAB 03: Backpropagation in Multilayer Neural Networks<br> <small>RÃ©da DEHAK<br> 06 January 2021</small> </center>\n",
    "\n",
    "The goal of this lab is :\n",
    "\n",
    "    - Understand neural networks and their layered architectures,\n",
    "    - Understand and implement backpropagation in `Numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Simple Case 2D problem \n",
    "### Import Data\n",
    "\n",
    "We will use the Wine dataset from UCI. These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of thirteen constituents found in each of the three types of wines.\n",
    "\n",
    "# Loading and Plotting Data\n",
    " \n",
    "First, we will use only two features from the data set: alcohol and ash (We can plot the solution in 2D space). The labels are supplied as an array of data with values from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.txt')\n",
    "\n",
    "X = data[['alcohol', 'flavanoids']].to_numpy()\n",
    "y = data[['class']].to_numpy().flatten() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 133 test: 45\n"
     ]
    }
   ],
   "source": [
    "# split data into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We fixe the random_state to have the same split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print('train:', len(X_train), 'test:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "MARKERS = ['+', 'x', '.']\n",
    "COLORS = ['red', 'green', 'blue']\n",
    "\n",
    "def plot_points(xy, labels):\n",
    "    \n",
    "    for i, label in enumerate(set(labels)):\n",
    "        points = np.array([xy[j,:] for j in range(len(xy)) if labels[j] == label])\n",
    "        marker = MARKERS[i % len(MARKERS)]\n",
    "        color = COLORS[i % len(COLORS)]\n",
    "        plt.scatter(points[:,0], points[:,1], marker=marker, color=color)\n",
    "\n",
    "plot_points(X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Normalization\n",
    "- Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.97285714  2.02120301]\n",
      "[0.82686706 1.00174963]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Data Normalization: mean = 0; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding for class label data\n",
    "\n",
    "First let's define a helper function to compute the one hot encoding of an integer array for a fixed number of classes (similar to keras' `to_categorical`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, n_classes):\n",
    "    # TODO:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "to_categorical(y=3, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot(y=3, n_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_categorical(y=[0, 4, 9, 1], num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot(y=[0, 4, 9, 1], n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The softmax function\n",
    "\n",
    "Now let's implement the softmax vector function:\n",
    "\n",
    "$$\n",
    "softmax(\\mathbf{x}) = \\frac{1}{\\sum_{i=1}^{n}{e^{x_i}}}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "  e^{x_1}\\\\\\\\\n",
    "  e^{x_2}\\\\\\\\\n",
    "  \\vdots\\\\\\\\\n",
    "  e^{x_n}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    # TODO:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that this works one vector at a time (and check that the components sum to one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax([10, 2, -3]))\n",
    "print(np.sum(softmax([10, 2, -3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a naive implementation of softmax might not be able process a batch of activations in a single call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[10, 2, -3],\n",
    "              [-1, 5, -20]])\n",
    "print(softmax(X))\n",
    "print(np.sum(softmax(X), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that given the true one-hot encoded class `Y_true` and some predicted probabilities `Y_pred` returns the negative log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1E-5\n",
    "def nllk(Y_true, Y_pred):\n",
    "    Y_true = np.asarray(Y_true)\n",
    "    Y_pred = np.asarray(Y_pred)\n",
    "    \n",
    "    # TODO\n",
    "    return 0. \n",
    "\n",
    "\n",
    "# Make sure that it works for a simple sample at a time\n",
    "print(nllk([1, 0, 0], [.99, 0.01, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the nll of a very confident yet bad prediction is a much higher positive number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nllk([1, 0, 0], [0.01, 0.01, .98]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `sigmoid` and its element-wise derivative `dsigmoid` functions:\n",
    "\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dsigmoid(x) = sigmoid(x) \\cdot (1 - sigmoid(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    # TODO\n",
    "    return X\n",
    "\n",
    "\n",
    "def dsigmoid(X):\n",
    "    # TODO\n",
    "    return X\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "plt.plot(x, sigmoid(x), label='sigmoid')\n",
    "plt.plot(x, dsigmoid(x), label='dsigmoid')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement `forward` and `forward_keep_all` functions for a model with a hidden layer with a sigmoid activation function:\n",
    "  - $\\mathbf{h} = sigmoid\\left(\\mathbf{W}_h^T \\hat{\\mathbf{x}}\\right)$\n",
    "  - $\\mathbf{y} = softmax\\left(\\mathbf{W}_o^T \\hat{\\mathbf{h}}\\right)$\n",
    "\n",
    "- Notes: \n",
    "  - `forward_keep_activations` is similar to forward, but also returns hidden activations and pre activations;\n",
    "\n",
    "- Implement the grad function to compute all gradients; check that the gradients are well defined;\n",
    "\n",
    "- Implement the `train` and `loss` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-8\n",
    "\n",
    "class NeuralNet():\n",
    "    \"\"\"MLP with 1 hidden layer with a sigmoid activation\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # TODO\n",
    "        self.W_h = None\n",
    "        self.W_o = None\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        # TODO\n",
    "        if len(X) == 1:\n",
    "            return np.random.uniform(size=self.output_size,\n",
    "                                     high=1.0-EPSILON, low=EPSILON)\n",
    "        else:\n",
    "            return np.random.uniform(size=(X.shape[0], self.output_size),\n",
    "                                     high=1.0-EPSILON, low=EPSILON)\n",
    "    \n",
    "    def forward_keep_activations(self, X):\n",
    "        # TODO\n",
    "        z_h = 0.\n",
    "        h = 0.\n",
    "        y = np.random.uniform(size=self.output_size,\n",
    "                              high=1.0-EPSILON, low=EPSILON)\n",
    "        return y, h, z_h\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        # TODO\n",
    "        return 42.\n",
    "\n",
    "    def grad_loss(self, x, y_true):\n",
    "        # TODO\n",
    "        return {\"dEdW_h\": 0., \"dEdW_o\": 0.}\n",
    "\n",
    "    \n",
    "    def train(self, x, y, learning_rate, l2 = 0.):\n",
    "        # One step of Backpropagation on x\n",
    "        # l2 is the L2 regularization coefficient \n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(X) == 1:\n",
    "            return np.argmax(self.forward(X))\n",
    "        else:\n",
    "            return np.argmax(self.forward(X), axis=1)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_preds = np.argmax(self.forward(X), axis=1)\n",
    "        return np.mean(y_preds == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the class NeuralNet to train a classifier on Wine Dataset, try different values for n_hidden (1,2,3 and 5), different Learning rate (0.1, 1, .5 and .01) and different l2 (0, 0.001, 0.005, 0.01) see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 5\n",
    "n_features = 2\n",
    "n_classes = 3\n",
    "modelWine = NeuralNet(n_features, n_hidden, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWine.loss(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWine.accuracy(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies, accuracies_test = [], [], []\n",
    "print(modelWine.loss(X_train, y_train))\n",
    "losses.append(modelWine.loss(X_train, y_train))\n",
    "accuracies.append(modelWine.accuracy(X_train, y_train))\n",
    "accuracies_test.append(modelWine.accuracy(X_test, y_test))\n",
    "\n",
    "print(\"Random init: train loss: %0.5f, train acc: %0.3f, test acc: %0.3f\"\n",
    "      % (losses[-1], accuracies[-1], accuracies_test[-1]))\n",
    "\n",
    "for epoch in range(15):\n",
    "    \n",
    "    for i in np.arange(X_train.shape[0]):\n",
    "        modelWine.train(X_train[i, :], y_train[i], .1)\n",
    "    print(modelWine.loss(X_train, y_train))\n",
    "    losses.append(modelWine.loss(X_train, y_train))\n",
    "    accuracies.append(modelWine.accuracy(X_train, y_train))\n",
    "    accuracies_test.append(modelWine.accuracy(X_test, y_test))\n",
    "    print(\"Epoch #%d, train loss: %0.5f, train acc: %0.3f, test acc: %0.3f\"\n",
    "          % (epoch + 1, losses[-1], accuracies[-1], accuracies_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Training loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(X, pred):\n",
    "    \n",
    "    x_min, x_max = X[:,0].min() - .1, X[:,0].max() + .1\n",
    "    y_min, y_max = X[:,1].min() - .1, X[:,1].max() + .1\n",
    "    \n",
    "    xs, ys = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 200),\n",
    "        np.linspace(y_min, y_max, 200)\n",
    "    )\n",
    "\n",
    "    xys = np.column_stack([xs.ravel(), ys.ravel()])\n",
    "    zs = pred(xys).reshape(xs.shape)\n",
    "    plt.contour(xs, ys, zs, colors='black')\n",
    "\n",
    "plot_points(X_train, y_train.flatten())\n",
    "plot_boundary(X_train, lambda x: model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batches\n",
    "\n",
    "- The current implementations of `train` and `grad_loss` function currently only accept a single sample at a time:\n",
    "    - implement MiniBatchNeuralNet class which supports training with a mini-batch of batch_size samples at a time instead of one,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchNeuralNet(NeuralNet):\n",
    "    \"\"\"MLP with 1 hidden layer with a sigmoid activation Using Mini Batch Learning\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - experiment with different sizes of batches,\n",
    "    - monitor the norm of the average gradients on the full training set at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2: Digit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAEpCAYAAACJL3coAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaMklEQVR4nO3de1CU1/0G8GcB2UXlpgFhKywGNV4QRfBCMGqUeKnakE6kMZqiNtHQJWptGsdOqxKraNNYm2gBrQUnRtFMxKSZKiIKNBoqgrReGgQFRYkiRgExWczu+f3hz40bQDmwN9bnM7N/7PHsnu8r8vjeznsUQggBIqI2crJ1AUTUuTA0iEgKQ4OIpDA0iEgKQ4OIpDA0iEgKQ4OIpDA0iEgKQ4OIpDA0LCQ9PR0KhQKVlZW2LsViOrKN48ePR0hIiFnrCQoKwty5c836ndQcQ4MIQHV1NebMmYOnnnoK7u7u8PLywsiRI7F9+3ZwpoUpF1sX4KheeeUVvPTSS1AqlbYuhdqgtrYWly9fxosvvojAwEDcvXsX2dnZmDt3LkpLS7F27Vpbl2g3GBoW4uzsDGdnZ1uXQW0UGhqK3Nxck7aEhATMmDED7733HlavXs2f5//j4YmFtHS8HxQUhOnTpyM3NxcRERFwc3PDkCFDjP9Y9+7diyFDhkClUiE8PBwnT540+c7//ve/mDt3Lp588kmoVCr4+flh/vz5uHHjRrPx74+hUqkQHByM1NRUrFq1CgqFolnfHTt2IDw8HG5ubujRowdeeuklVFVVtWu7P/nkE0ybNg1qtRpKpRLBwcFYvXo19Hp9i/2Liorw9NNPw83NDX369EFKSkqzPjqdDitXrkTfvn2hVCoREBCAt956Czqd7pH1nD9/HufPn2/XtgD3fmZ37txBU1NTu7/D0XBPw8rKy8vx8ssvY+HChZgzZw7+9Kc/YcaMGUhJScFvf/tb/PKXvwQAJCUlITY2FqWlpXByupft2dnZuHDhAubNmwc/Pz+cOXMGW7ZswZkzZ1BQUGAMhJMnT2LKlCnw9/dHYmIi9Ho93n77bfj4+DSrZ82aNfj973+P2NhYvPrqq7h+/Tref/99jB07FidPnoSXl5fU9qWnp6N79+5YunQpunfvjsOHD2PFihWor6/HO++8Y9L35s2b+PGPf4zY2FjMmjULe/bsQXx8PFxdXTF//nwAgMFgwE9+8hN8/vnnWLBgAQYOHIhTp07hz3/+M86dO4d9+/Y9tJ6JEycCQJtP1n7zzTdobGzE7du3kZeXh7S0NERGRsLNzU3q78GhCbKItLQ0AUBUVFQY2zQajQAgjh07ZmzLysoSAISbm5u4ePGisT01NVUAEEeOHDG23blzp9k4u3btEgBEfn6+sW3GjBmia9eu4sqVK8a2srIy4eLiIh78kVdWVgpnZ2exZs0ak+88deqUcHFxadbelm1sqcaFCxeKrl27im+//dbYNm7cOAFAvPvuu8Y2nU4nhg0bJnx9fUVTU5MQQogPPvhAODk5iX/9618m35mSkiIAiKNHjxrbNBqNiIuLM+mn0WiERqN56HY8KCkpSQAwviZOnCguXbrU5s8/Dnh4YmWDBg1CZGSk8f2oUaMAABMmTEBgYGCz9gsXLhjbHvzf7ttvv0VtbS1Gjx4NACguLgYA6PV6HDp0CDExMVCr1cb+ffv2xdSpU01q2bt3LwwGA2JjY1FbW2t8+fn5oV+/fjhy5Ij09j1YY0NDA2pra/HMM8/gzp07+PLLL036uri4YOHChcb3rq6uWLhwIWpqalBUVAQA+OijjzBw4EAMGDDApMYJEyYAwCNrrKyslLokPGvWLGRnZ2Pnzp14+eWXAdzb+6Dv8fDEyh4MBgDw9PQEAAQEBLTYfvPmTWPb119/jcTERGRkZKCmpsakf11dHQCgpqYG33zzDfr27dts7B+2lZWVQQiBfv36tVhrly5d2rJJJs6cOYPf/e53OHz4MOrr61us8T61Wo1u3bqZtPXv3x/AvV/20aNHo6ysDP/73/9aPLQC0OzvoaM0Gg00Gg2AewGyYMECREdHo7S0lIco/4+hYWWtnYFvrV08cI9AbGwsjh07ht/85jcYNmwYunfvDoPBgClTpsBgMEjXYjAYoFAosH///hbH7969u9T33bp1C+PGjYOHhwfefvttBAcHQ6VSobi4GMuWLWt3jUOGDMGGDRta/PMfhq25vfjii9i6dSvy8/MxefJki47VWTA0OombN28iJycHiYmJWLFihbG9rKzMpJ+vry9UKhXKy8ubfccP24KDgyGEQJ8+fYz/w3dEbm4ubty4gb1792Ls2LHG9oqKihb7V1dXo7Gx0WRv49y5cwDuXbW4X+N//vMfTJw4scUrP5Z2/9Dkh3tJjzOe0+gk7u8JiB/cnbhx48Zm/aKjo7Fv3z5UV1cb28vLy7F//36Tvj/96U/h7OyMxMTEZt8rhGjxUq5sjU1NTfjrX//aYv/vvvsOqampJn1TU1Ph4+OD8PBwAPf2rq5cuYKtW7c2+/z9Kx0P09ZLrtevX2+xfdu2bVAoFBg+fPgjv+NxwT2NTsLDwwNjx47FH//4R9y9exc/+tGPcPDgwRb/F1+1ahUOHjyIqKgoxMfHQ6/XY9OmTQgJCUFJSYmxX3BwMP7whz9g+fLlqKysRExMDNzd3VFRUYHMzEwsWLAAb775ZptrfPrpp+Ht7Y24uDgsWrQICoUCH3zwQau3YavVaqxfvx6VlZXo378/du/ejZKSEmzZssV4PuWVV17Bnj178Prrr+PIkSOIioqCXq/Hl19+iT179iArKwsRERGt1tTWS65r1qzB0aNHMWXKFAQGBuLrr7/Gxx9/jMLCQrzxxhstniN6bNnuwo1ja+2S67Rp05r1BSC0Wq1JW0VFhQAg3nnnHWPb5cuXxQsvvCC8vLyEp6enmDlzpqiurhYAxMqVK00+n5OTI8LCwoSrq6sIDg4Wf/vb38Svf/1roVKpmo3/8ccfizFjxohu3bqJbt26iQEDBgitVitKS0ult/Ho0aNi9OjRws3NTajVavHWW28ZLys/ePl43LhxYvDgweLEiRMiMjJSqFQqodFoxKZNm5qN09TUJNavXy8GDx4slEql8Pb2FuHh4SIxMVHU1dWZ/P2295LrwYMHxfTp04VarRZdunQR7u7uIioqSqSlpQmDwfDIzz9OFEJwNs7jIiYmBmfOnGl2HoRIBs9pOKgf3ltQVlaGf/7znxg/frxtCiKHwT0NB+Xv72+cp3Lx4kUkJydDp9Ph5MmTrd6XQdQWPBHqoKZMmYJdu3bh6tWrUCqViIyMxNq1axkY1GHc0yAiKTynQURSGBpEJMXq5zQMBgOqq6vh7u5uk9uCiahlQgg0NDRArVYbn+HSEquHRnV1tcUnGRFR+1VVVaF3796t/rnVQ8Pd3R3AvcI8PDysPbxVLVu2zOpjtvS4PEsy9zIEbXH/6WbWNHv2bKuPaW319fUICAgw/o62xuqhcf+QxMPDw+FD43F4ErktHrZri+daOPq/1Qc96rQBT4QSkRSGBhFJYWgQkRSGBhFJYWgQkRSGBhFJYWgQkZR2hcbmzZsRFBQElUqFUaNG4fjx4+aui4jslHRo7N69G0uXLsXKlStRXFyMoUOHYvLkyWZftIaI7JN0aGzYsAGvvfYa5s2bh0GDBiElJQVdu3bF3//+d0vUR0R2Rio0mpqaUFRUhOjo6O+/wMkJ0dHR+OKLL8xeHBHZH6m5J7W1tdDr9ejVq5dJe69evZot7nufTqeDTqczvv/h+p5E1LlY/OpJUlISPD09jS9Oiyfq3KRC44knnoCzszOuXbtm0n7t2jX4+fm1+Jnly5ejrq7O+Kqqqmp/tURkc1Kh4erqivDwcOTk5BjbDAYDcnJyEBkZ2eJnlEqlcRr84zAdnsjRST9PY+nSpYiLi0NERARGjhyJjRs3orGxEfPmzbNEfURkZ6RD42c/+xmuX7+OFStW4OrVqxg2bBgOHDjQ7OQoETmmdj25KyEhAQkJCeauhYg6Ac49ISIpDA0iksLQICIpDA0iksLQICIpDA0iksLQICIpDA0ikqIQQghrDlhfXw9PT0/U1dU5/DyU9PR0q4/p7e1t1fFiYmKsOp6tWPnXxCba+rvJPQ0iksLQICIpDA0iksLQICIpDA0iksLQICIpDA0iksLQICIpDA0ikiIdGvn5+ZgxYwbUajUUCgX27dtngbKIyF5Jh0ZjYyOGDh2KzZs3W6IeIrJz0g8Wnjp1KqZOnWqJWoioE+A5DSKS0q4lDGRwAWgix8IFoIlIisVDgwtAEzkWix+eKJVKKJVKSw9DRFYiHRq3b99GeXm58X1FRQVKSkrQo0cPBAYGmrU4IrI/0qFx4sQJPPvss8b3S5cuBQDExcXZ5PF2RGRd0qExfvz4x+J5iUTUMt6nQURSGBpEJIWhQURSGBpEJIWhQURSGBpEJIWhQURSGBpEJMXic08eZ3PnzrX6mKtWrbLqeJ6enlYdDwC2b99u9THpe9zTICIpDA0iksLQICIpDA0iksLQICIpDA0iksLQICIpDA0iksLQICIpUqGRlJSEESNGwN3dHb6+voiJiUFpaamlaiMiOyQVGnl5edBqtSgoKEB2djbu3r2LSZMmobGx0VL1EZGdkZp7cuDAAZP36enp8PX1RVFREcaOHWvWwojIPnVowlpdXR0AoEePHq324VquRI6l3SdCDQYDlixZgqioKISEhLTaj2u5EjmWdoeGVqvF6dOnkZGR8dB+XMuVyLG06/AkISEBn332GfLz89G7d++H9uVarkSORSo0hBB44403kJmZidzcXPTp08dSdRGRnZIKDa1Wi507d+KTTz6Bu7s7rl69CuDe05vc3NwsUiAR2RepcxrJycmoq6vD+PHj4e/vb3zt3r3bUvURkZ2RPjwhoscb554QkRSGBhFJYWgQkRSGBhFJYWgQkRSGBhFJYWgQkRSGBhFJ4QLQDiYsLMyq43l5eVl1PADQaDRWH5O+xz0NIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpIi/YzQ0NBQeHh4wMPDA5GRkdi/f7+laiMiOyQVGr1798a6detQVFSEEydOYMKECXj++edx5swZS9VHRHZGau7JjBkzTN6vWbMGycnJKCgowODBg81aGBHZp3ZPWNPr9fjoo4/Q2NiIyMjIVvtxAWgixyJ9IvTUqVPo3r07lEolXn/9dWRmZmLQoEGt9ucC0ESORTo0nnrqKZSUlODf//434uPjERcXh7Nnz7banwtAEzkW6cMTV1dX9O3bFwAQHh6OwsJC/OUvf0FqamqL/bkANJFj6fB9GgaDweScBRE5Nqk9jeXLl2Pq1KkIDAxEQ0MDdu7cidzcXGRlZVmqPiKyM1KhUVNTg5///Of46quv4OnpidDQUGRlZeG5556zVH1EZGekQmPbtm2WqoOIOgnOPSEiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKVzL1cE8//zzVh3vyJEjVh0PAMaPH2/1MUtKSqw+ZlBQkNXHbAvuaRCRFIYGEUlhaBCRFIYGEUlhaBCRFIYGEUlhaBCRFIYGEUlhaBCRFIYGEUnpUGisW7cOCoUCS5YsMVM5RGTv2h0ahYWFSE1NRWhoqDnrISI7167QuH37NmbPno2tW7fC29vb3DURkR1rV2hotVpMmzYN0dHRj+yr0+lQX19v8iKizkt6anxGRgaKi4tRWFjYpv5JSUlITEyULoyI7JPUnkZVVRUWL16MDz/8ECqVqk2f4QLQRI5Fak+jqKgINTU1GD58uLFNr9cjPz8fmzZtgk6ng7Ozs8lnuAA0kWORCo2JEyfi1KlTJm3z5s3DgAEDsGzZsmaBQUSORyo03N3dERISYtLWrVs39OzZs1k7ETkm3hFKRFI6/GDh3NxcM5RBRJ0F9zSISApDg4ikMDSISApDg4ikMDSISApDg4ikMDSISIpCCCGsOWB9fT08PT1RV1cHDw8Paw5NDiImJsbqY966dcvqY1r7Hqi2/m5yT4OIpDA0iEgKQ4OIpDA0iEgKQ4OIpDA0iEgKQ4OIpDA0iEgKQ4OIpDA0iEiKVGisWrUKCoXC5DVgwABL1UZEdkj6GaGDBw/GoUOHvv8Clw4/ZpSIOhHp33gXFxf4+flZohYi6gSkz2mUlZVBrVbjySefxOzZs3Hp0qWH9ucC0ESORSo0Ro0ahfT0dBw4cADJycmoqKjAM888g4aGhlY/k5SUBE9PT+MrICCgw0UTke106Hkat27dgkajwYYNG/CLX/yixT46nQ46nc74vr6+HgEBAXyeBrUbn6dhGW19nkaHzmJ6eXmhf//+KC8vb7UPF4Amciwduk/j9u3bOH/+PPz9/c1VDxHZOanQePPNN5GXl4fKykocO3YML7zwApydnTFr1ixL1UdEdkbq8OTy5cuYNWsWbty4AR8fH4wZMwYFBQXw8fGxVH1EZGekQiMjI8NSdRBRJ8G5J0QkhaFBRFIYGkQkhaFBRFIYGkQkhaFBRFIYGkQkhU/QsSBrTziyxZglJSVWHQ+wzd/rsGHDrD6mveKeBhFJYWgQkRSGBhFJYWgQkRSGBhFJYWgQkRSGBhFJYWgQkRSGBhFJYWgQkRTp0Lhy5QrmzJmDnj17ws3NDUOGDMGJEycsURsR2SGpuSc3b95EVFQUnn32Wezfvx8+Pj4oKyuDt7e3peojIjsjFRrr169HQEAA0tLSjG19+vQxe1FEZL+kDk8+/fRTREREYObMmfD19UVYWBi2bt360M9wAWgixyIVGhcuXEBycjL69euHrKwsxMfHY9GiRdi+fXurn+EC0ESORSo0DAYDhg8fjrVr1yIsLAwLFizAa6+9hpSUlFY/s3z5ctTV1RlfVVVVHS6aiGxHKjT8/f0xaNAgk7aBAwfi0qVLrX5GqVTCw8PD5EVEnZdUaERFRaG0tNSk7dy5c9BoNGYtiojsl1Ro/OpXv0JBQQHWrl2L8vJy7Ny5E1u2bIFWq7VUfURkZ6RCY8SIEcjMzMSuXbsQEhKC1atXY+PGjZg9e7al6iMiOyP9YOHp06dj+vTplqiFiDoBzj0hIikMDSKSwtAgIikMDSKSwtAgIikMDSKSwtAgIilcANqCNm7caPUxrb0gc1BQkFXHA4AlS5ZYfcxVq1ZZfUx7xT0NIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpIiFRpBQUFQKBTNXnxGKNHjQ+o28sLCQuj1euP706dP47nnnsPMmTPNXhgR2Sep0PDx8TF5v27dOgQHB2PcuHFmLYqI7Fe7z2k0NTVhx44dmD9/PhQKhTlrIiI71u5Zrvv27cOtW7cwd+7ch/bT6XTQ6XTG91wAmqhza/eexrZt2zB16lSo1eqH9uMC0ESOpV2hcfHiRRw6dAivvvrqI/tyAWgix9Kuw5O0tDT4+vpi2rRpj+yrVCqhVCrbMwwR2SHpPQ2DwYC0tDTExcXBxYUP/iJ63EiHxqFDh3Dp0iXMnz/fEvUQkZ2T3lWYNGkShBCWqIWIOgHOPSEiKQwNIpLC0CAiKQwNIpLC0CAiKQwNIpLC0CAiKVa/pfP+PR6Pw2zXu3fvWn1Mg8Fg1fG+++47q44HwGTWtLU8Dv9e72/jo+7DUggr36l1+fJlznQlsmNVVVXo3bt3q39u9dAwGAyorq6Gu7u71MN76uvrERAQgKqqKnh4eFiwQtvidjqOzraNQgg0NDRArVbDyan1MxdWPzxxcnJ6aIo9ioeHR6f4AXQUt9NxdKZt9PT0fGQfngglIikMDSKS0mlCQ6lUYuXKlQ7/QB9up+Nw1G20+olQIurcOs2eBhHZB4YGEUlhaBCRFIYGEUnpNKGxefNmBAUFQaVSYdSoUTh+/LitSzKbpKQkjBgxAu7u7vD19UVMTAxKS0ttXZbFrVu3DgqFAkuWLLF1KWZ35coVzJkzBz179oSbmxuGDBmCEydO2Loss+gUobF7924sXboUK1euRHFxMYYOHYrJkyejpqbG1qWZRV5eHrRaLQoKCpCdnY27d+9i0qRJaGxstHVpFlNYWIjU1FSEhobauhSzu3nzJqKiotClSxfs378fZ8+exbvvvgtvb29bl2YeohMYOXKk0Gq1xvd6vV6o1WqRlJRkw6osp6amRgAQeXl5ti7FIhoaGkS/fv1Edna2GDdunFi8eLGtSzKrZcuWiTFjxti6DIux+z2NpqYmFBUVITo62tjm5OSE6OhofPHFFzaszHLq6uoAAD169LBxJZah1Woxbdo0k5+pI/n0008RERGBmTNnwtfXF2FhYdi6dautyzIbuw+N2tpa6PV69OrVy6S9V69euHr1qo2qshyDwYAlS5YgKioKISEhti7H7DIyMlBcXIykpCRbl2IxFy5cQHJyMvr164esrCzEx8dj0aJF2L59u61LMwuuq2hntFotTp8+jc8//9zWpZhdVVUVFi9ejOzsbKhUKluXYzEGgwERERFYu3YtACAsLAynT59GSkoK4uLibFxdx9n9nsYTTzwBZ2dnXLt2zaT92rVr8PPzs1FVlpGQkIDPPvsMR44c6dDjA+xVUVERampqMHz4cLi4uMDFxQV5eXl477334OLiAr1eb+sSzcLf3x+DBg0yaRs4cCAuXbpko4rMy+5Dw9XVFeHh4cjJyTG2GQwG5OTkIDIy0oaVmY8QAgkJCcjMzMThw4fRp08fW5dkERMnTsSpU6dQUlJifEVERGD27NkoKSmBs7OzrUs0i6ioqGaXzM+dOweNRmOjiszM1mdi2yIjI0MolUqRnp4uzp49KxYsWCC8vLzE1atXbV2aWcTHxwtPT0+Rm5srvvrqK+Przp07ti7N4hzx6snx48eFi4uLWLNmjSgrKxMffvih6Nq1q9ixY4etSzOLThEaQgjx/vvvi8DAQOHq6ipGjhwpCgoKbF2S2QBo8ZWWlmbr0izOEUNDCCH+8Y9/iJCQEKFUKsWAAQPEli1bbF2S2XBqPBFJsftzGkRkXxgaRCSFoUFEUhgaRCSFoUFEUhgaRCSFoUFEUhgaRCSFoUFEUhgaRCSFoUFEUhgaRCTl/wCL1djsGFbqMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(digits.images[sample_index], cmap=plt.cm.gray_r,\n",
    "           interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % digits.target[sample_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Normalization\n",
    "- Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 2.98624754e-01 5.19253438e+00 1.18428291e+01\n",
      " 1.18565815e+01 5.81008513e+00 1.34774067e+00 1.19187950e-01\n",
      " 6.54878847e-03 1.99345121e+00 1.03464309e+01 1.19305828e+01\n",
      " 1.02626064e+01 8.20497708e+00 1.84348396e+00 9.88867060e-02\n",
      " 3.27439424e-03 2.61624100e+00 9.83497053e+00 6.87098887e+00\n",
      " 7.11263916e+00 7.83759005e+00 1.75376555e+00 4.45317616e-02\n",
      " 1.30975769e-03 2.48788474e+00 9.04453176e+00 8.73280943e+00\n",
      " 9.98231827e+00 7.57105435e+00 2.26850033e+00 2.61951539e-03\n",
      " 0.00000000e+00 2.36149312e+00 7.68369352e+00 9.07924034e+00\n",
      " 1.03713163e+01 8.79240341e+00 2.89980354e+00 0.00000000e+00\n",
      " 8.51342502e-03 1.57039948e+00 6.84937787e+00 7.22855272e+00\n",
      " 7.65029470e+00 8.26522593e+00 3.48592010e+00 2.61951539e-02\n",
      " 8.51342502e-03 6.83693517e-01 7.49312377e+00 9.56516045e+00\n",
      " 9.36869679e+00 8.77668631e+00 3.76686313e+00 2.08906352e-01\n",
      " 6.54878847e-04 2.78978389e-01 5.53700065e+00 1.20595940e+01\n",
      " 1.17832351e+01 6.81990832e+00 2.07465619e+00 3.42501637e-01]\n",
      "[1.         0.91047426 4.7374689  4.2596074  4.30740756 5.68243448\n",
      " 3.29715288 1.008902   0.10215271 3.21973438 5.4108079  3.99431828\n",
      " 4.76326914 6.05761692 3.54497651 0.7879529  0.06762714 3.5953762\n",
      " 5.75591791 5.79499053 6.17007499 6.20389862 3.17131632 0.42435037\n",
      " 0.03616687 3.17586741 6.22714405 5.87843364 6.12768087 5.88661918\n",
      " 3.63962    0.05111412 1.         3.51146089 6.35184392 6.26198479\n",
      " 5.92379357 5.86282789 3.54313582 1.         0.13754638 2.96676443\n",
      " 6.52281056 6.46350061 6.27357424 5.66458135 4.32560252 0.31021909\n",
      " 0.22145752 1.71021508 5.62991342 5.23221519 5.31295785 6.03074701\n",
      " 4.9404445  0.9965096  0.02558222 0.94066093 5.07505293 4.37977563\n",
      " 4.96650551 5.92097458 4.05023215 1.78068506]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.15, random_state=37)\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 4\u001b[0m modelDigit \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNet\u001b[49m(n_features, n_hidden, n_classes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NeuralNet' is not defined"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "n_classes = 10\n",
    "n_features = 64\n",
    "modelDigit = NeuralNet(n_features, n_hidden, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDigit.loss(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDigit.accuracy(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     ax1\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDigit class\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     ax1\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m---> 18\u001b[0m plot_prediction(\u001b[43mmodel\u001b[49m, sample_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_prediction(model, sample_idx = 0, classes = range(10)):\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\n",
    "\n",
    "    ax0.imshow(scaler.inverse_transform(X_test[sample_idx]).reshape(8, 8), cmap = plt.cm.gray_r,\n",
    "               interpolation = 'nearest')\n",
    "    ax0.set_title(\"True image label: %d\" % y_test[sample_idx]);\n",
    "\n",
    "\n",
    "    ax1.bar(classes, one_hot(y_test[sample_idx], n_classes=len(classes)), label = 'true')\n",
    "    ax1.bar(classes, model.forward(X_test[sample_idx]), label = 'prediction', color = \"red\")\n",
    "    ax1.set_xticks(classes)\n",
    "    prediction = model.predict(X_test[sample_idx])\n",
    "    ax1.set_title('Output probabilities (prediction: %d)'\n",
    "                  % prediction)\n",
    "    ax1.set_xlabel('Digit class')\n",
    "    ax1.legend()\n",
    "\n",
    "plot_prediction(model, sample_idx=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies, accuracies_test = [], [], []\n",
    "losses.append(modelDigit.loss(X_train, y_train))\n",
    "accuracies.append(modelDigit.accuracy(X_train, y_train))\n",
    "accuracies_test.append(modelDigit.accuracy(X_test, y_test))\n",
    "\n",
    "print(\"Random init: train loss: %0.5f, train acc: %0.3f, test acc: %0.3f\"\n",
    "      % (losses[-1], accuracies[-1], accuracies_test[-1]))\n",
    "\n",
    "for epoch in range(15):\n",
    "    for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "        modelDigit.train(x, y, 0.1)\n",
    "\n",
    "    losses.append(modelDigit.loss(X_train, y_train))\n",
    "    accuracies.append(modelDigit.accuracy(X_train, y_train))\n",
    "    accuracies_test.append(modelDigit.accuracy(X_test, y_test))\n",
    "    print(\"Epoch #%d, train loss: %0.5f, train acc: %0.3f, test acc: %0.3f\"\n",
    "          % (epoch + 1, losses[-1], accuracies[-1], accuracies_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Training loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, label = 'train')\n",
    "plt.plot(accuracies_test, label = 'test')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc = 'best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(model, sample_idx = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look at worst prediction errors:\n",
    "\n",
    "    - Use numpy to find test samples for which the model made the worst predictions,\n",
    "    - Use the `plot_prediction` to look at the model predictions on those,\n",
    "    - Would you have done any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Keras\n",
    "\n",
    "- You can now use keras to implement and train the same network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.8094\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9424\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9528\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9614\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9633\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9587\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9745\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9862\n",
      "Epoch 9/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9856\n",
      "Epoch 10/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9882\n",
      "Epoch 11/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9902\n",
      "Epoch 12/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9862\n",
      "Epoch 13/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9915\n",
      "Epoch 14/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9817\n",
      "Epoch 15/15\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1398f1fa0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "n_features = 8 * 8\n",
    "n_classes = 10\n",
    "n_hidden = 10\n",
    "\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(n_hidden, input_dim = n_features, activation = 'sigmoid'))\n",
    "keras_model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "keras_model.compile(optimizer = SGD(learning_rate = 3),\n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "keras_model.fit(X_train, to_categorical(y_train), epochs = 15, batch_size = 16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check that the Keras model can approximately reproduce the behavior of the Numpy model when using similar hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using keras, add a second hidden Layer to keras_model model and learn the hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is the model overfitting or underfitting? (ensure that the model has fully converged by increasing the number of epochs to 50 or more if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39tf2",
   "language": "python",
   "name": "py39tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
